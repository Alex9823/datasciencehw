{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DSassignment5.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_FYtCeHhuBZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX_G9-tClmn2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from sklearn import metrics\n",
        "import sys\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Dense , Input , LSTM , Embedding, Dropout , Activation, GRU, Flatten\n",
        "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Convolution1D\n",
        "from keras import initializers, regularizers, constraints, optimizers, layers\n",
        "\n",
        "import re\n",
        "\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMNXHkl5sKiS",
        "colab_type": "code",
        "outputId": "246ce1ec-7a07-42ea-be96-29b60de1961e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPPriwAIvr66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stop_words=nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tABBPiZ6lcS9",
        "colab_type": "code",
        "outputId": "5fdaced7-1b1e-4f5c-a658-ff720f9426c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvtUHjj3pyjF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path = ('drive/My Drive/imdb_master.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-mXHegDizEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = pd.read_csv(path, index_col=0, encoding='latin-1')\n",
        "corpus = corpus.drop([\"file\"], axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMYdo73qmkot",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test = corpus.loc[corpus[\"type\"] == \"test\"].drop([\"type\"], axis=1)\n",
        "train = corpus.loc[corpus[\"type\"] == \"train\"].drop([\"type\"], axis=1)\n",
        "unsup_texts = list(train.loc[train[\"label\"] == \"unsup\", \"review\"])\n",
        "train = train.loc[train[\"label\"] != \"unsup\"]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_NIYtfyrPE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train.to_csv(\"imdb_train.csv\", encoding=\"utf-8\")\n",
        "test.to_csv(\"imdb_test.csv\", encoding=\"utf-8\")\n",
        "corpus.to_csv(\"imdb_corpus.csv\", encoding=\"utf-8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozC-cm3FrhEp",
        "colab_type": "code",
        "outputId": "72c6e943-f852-40f5-c0bf-7c4f67096ebb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "train['label'] "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25000    neg\n",
              "25001    neg\n",
              "25002    neg\n",
              "25003    neg\n",
              "25004    neg\n",
              "        ... \n",
              "49995    pos\n",
              "49996    pos\n",
              "49997    pos\n",
              "49998    pos\n",
              "49999    pos\n",
              "Name: label, Length: 25000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 157
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07EHwAeZu2PR",
        "colab_type": "code",
        "outputId": "acc3e22f-7e59-4923-b2bd-8c44749ff30e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(test), len(train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 25000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F9Ldc1yysHG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['label'] = train['label'].apply(lambda x : 0 if x=='neg' else 1)\n",
        "test['label'] = test['label'].apply(lambda x : 0 if x=='neg' else 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhbNv-d03taW",
        "colab_type": "code",
        "outputId": "f8448bf8-e64e-47ca-8b78-ff594ea70824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25000</th>\n",
              "      <td>Story of a man who has unnatural feelings for ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25001</th>\n",
              "      <td>Airport '77 starts as a brand new luxury 747 p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25002</th>\n",
              "      <td>This film lacked something I couldn't put my f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25003</th>\n",
              "      <td>Sorry everyone,,, I know this is supposed to b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25004</th>\n",
              "      <td>When I was little my parents took me along to ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>Seeing as the vote average was pretty low, and...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>The plot had some wretched, unbelievable twist...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>I am amazed at how this movie(and most others ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>A Christmas Together actually came before my t...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>Working-class romantic drama from director Mar...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25000 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review  label\n",
              "25000  Story of a man who has unnatural feelings for ...      0\n",
              "25001  Airport '77 starts as a brand new luxury 747 p...      0\n",
              "25002  This film lacked something I couldn't put my f...      0\n",
              "25003  Sorry everyone,,, I know this is supposed to b...      0\n",
              "25004  When I was little my parents took me along to ...      0\n",
              "...                                                  ...    ...\n",
              "49995  Seeing as the vote average was pretty low, and...      1\n",
              "49996  The plot had some wretched, unbelievable twist...      1\n",
              "49997  I am amazed at how this movie(and most others ...      1\n",
              "49998  A Christmas Together actually came before my t...      1\n",
              "49999  Working-class romantic drama from director Mar...      1\n",
              "\n",
              "[25000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yW0cLNNgvDAp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-KghsO5vDDW",
        "colab_type": "code",
        "outputId": "94d48e86-4e23-469c-e39c-0f7e282ff4d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "nltk.download('wordnet')\n",
        "def tokenize(text):\n",
        "    return token.tokenize(text)\n",
        "\n",
        "def clear(text):\n",
        "    text = text.lower()\n",
        "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
        "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
        "    text = [word for word in text if not word in stop_words]\n",
        "    text = \" \".join(text)\n",
        "    return text\n",
        "    \n",
        "def normalize(text):\n",
        "    words = [morph.parse(word)[0].normal_form for word in tokenize(clear(text))]\n",
        "    return words\n",
        "\n",
        "train['processed'] = train.review.apply(lambda x: normalize(x))\n",
        "test['processed'] = test.review.apply(lambda x: normolize(x))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy_QNB50v2XG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 10000\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(train['processed'])\n",
        "list_tokenized_train = tokenizer.texts_to_sequences(train['processed'])\n",
        "\n",
        "maxlen = 150\n",
        "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
        "y = train['label']\n",
        "\n",
        "embed_size = 256\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_features, embed_size))\n",
        "model.add(Bidirectional(LSTM(64, return_sequences=True)))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(40, activation=\"relu\"))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "batch_size = 200\n",
        "epochs = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IErUhguoymR9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMYkIQn1vDGF",
        "colab_type": "code",
        "outputId": "1192b46a-cf37-4ccc-d56c-1a7346135b6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "model.fit(X_t,y, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/2\n",
            "20000/20000 [==============================] - 170s 9ms/step - loss: 0.4897 - acc: 0.7604 - val_loss: 0.6384 - val_acc: 0.7336\n",
            "Epoch 2/2\n",
            "20000/20000 [==============================] - 166s 8ms/step - loss: 0.2176 - acc: 0.9169 - val_loss: 0.6989 - val_acc: 0.7158\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f99089675c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvgx6aakvDIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_tokenized_test = tokenizer.texts_to_sequences(test['processed'])\n",
        "maxlen = 150\n",
        "X_test = pad_sequences(list_tokenized_test, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBrJtGuRvDKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction(x):\n",
        "    if x>=0.4:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "preds = [take_pred(x[0]) for x in model.predict(X_test)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_DZy1KOzH23Q",
        "colab_type": "text"
      },
      "source": [
        "#**Accuracy** **score**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1PFd9wE2kKY",
        "colab_type": "code",
        "outputId": "0b4e773e-b1f1-4379-9b01-c120fd2f13fe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "(predictions == test['label'].values).mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.85672"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 184
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6fop8ma2kPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycfiU7gV2kXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}